{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS S3 Buckets Example\n",
    "\n",
    "## Assumptions\n",
    " - Working from a Jupyter notebook locally\n",
    " - Not concerned about access or keeping data private\n",
    "\n",
    "For the purpose of this lesson, the `wine_classifier.pickle` file has already been uploaded to Erin's AWS account.  To make your pickle file available from code, you would need to make an account and upload the file.\n",
    "\n",
    "## CLI Interface\n",
    "Installation instructions [here](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html), CLI docs [here](https://docs.aws.amazon.com/cli/latest/reference/s3/).  You will need to use this to upload large files (over 160MB I believe) but it's clunkier than integrating directly into Python and won't work with all deployment techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp s3://flatiron-ds-2020-04-13/wine_classifier.pickle wine_classifier.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "BUCKET = \"flatiron-ds-2020-04-13\"\n",
    "PICKLE_FILE = \"wine_classifier.pickle\"\n",
    "CSV_FILE = \"wine.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boto 3\n",
    "This is an SDK for connecting Python to S3 buckets.  Docs [here](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html). This is a good tool for large pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install boto3 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "obj = s3.Object(BUCKET, PICKLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_body = obj.get()[\"Body\"].read()\n",
    "response_body[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.loads(response_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "If you are trying to load a CSV rather than a pickle, you can do that directly in Pandas!  First you'll need to install `S3FS` (docs [here](https://s3fs.readthedocs.io/en/latest/)) which allows Python to access S3 buckets like they are part of the local file system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install s3fs -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "file_path = path.join(\"s3://\", BUCKET, CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (prework-labs)",
   "language": "python",
   "name": "prework-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
